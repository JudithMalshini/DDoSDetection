{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x6HsaxaDCRYr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel,VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJqb6MheDbcU",
    "outputId": "8032b36d-7ba8-4085-df00-904156d019e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] Created folder\n"
     ]
    }
   ],
   "source": [
    "DATA_COUNT=1000 # define no of data per class\n",
    "NO_CLASSES=11  # no of ddos classes in the dataset\n",
    "date = date.today()\n",
    "folder_path = ''\n",
    "dataset1_path=os.path.join(folder_path,\"data1\")\n",
    "\n",
    "result_main_path=os.path.join(folder_path,\"results\")\n",
    "results_path=os.path.join(result_main_path,str(date))\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(results_path)\n",
    "    print('[Success] Created folder')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSSQL =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_sql = pd.read_csv(os.path.join(dataset1_path,'DrDoS_MSSQL.csv')) #read ddos mssql file\n",
    "dataset_sql.replace([np.inf, -np.inf], np.nan, inplace=True)  # replace missings values with nan(not available)\n",
    "dataset_sql = dataset_sql.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_sql.replace(np.nan, 0, inplace=True)\n",
    "dataset_sql[' Label'].replace({\"BENIGN\": 0, \"DrDoS_MSSQL\": 1}, inplace=True)# replace labels if label is benign with 0 and mssql with 1\n",
    "\n",
    "bengins_sql=dataset_sql.loc[dataset_sql[' Label']==0] # extract rows which label is 0 (rows which label is bengin)\n",
    "\n",
    "mssql=dataset_sql.loc[dataset_sql[' Label']==1] # extract rows whihc label is 1 \n",
    "mssql=mssql.sample(n=DATA_COUNT, random_state=40)#extract number of data defined in the data count(1000) which has label as 1\n",
    "\n",
    "bengins_sql=bengins_sql.sample(n=int(DATA_COUNT/NO_CLASSES), random_state=40)# extract 1000/11 number of data which label is 0 which are benings. \n",
    "bengins=bengins_sql#bengins dataset creation starting step\n",
    "\n",
    "del dataset_sql#delete the ealier read dataset \n",
    "del bengins_sql\n",
    "# bengins.shape, syns.shape, udps.shape,udpLags.shape,dns.shape,ldap.shape,mssql.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SSDP =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_ssdp = pd.read_csv(os.path.join(dataset1_path,'DrDoS_SSDP.csv'))\n",
    "dataset_ssdp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_ssdp = dataset_ssdp.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_ssdp.replace(np.nan, 0, inplace=True)\n",
    "dataset_ssdp[' Label'].replace({\"BENIGN\": 0, \"DrDoS_SSDP\": 2}, inplace=True)\n",
    "\n",
    "bengins_ssdp=dataset_ssdp.loc[dataset_ssdp[' Label']==0]\n",
    "\n",
    "ssdp=dataset_ssdp.loc[dataset_ssdp[' Label']==2]\n",
    "ssdp=ssdp.sample(n=DATA_COUNT, random_state=40)\n",
    "\n",
    "bengins_ssdp=bengins_ssdp.sample(n=int(DATA_COUNT/10), random_state=40)\n",
    "bengins = bengins.append(bengins_ssdp)#append to the bengins dataset\n",
    "del dataset_ssdp\n",
    "del bengins_ssdp\n",
    "# bengins.shape, syns.shape,udps.shape,udpLags.shape,dns.shape,ldap.shape,mssql.shape,netbios.shape,ntp.shape,snmp.shape,ssdp.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_dns = pd.read_csv(os.path.join(dataset1_path,'DrDoS_DNS.csv'))\n",
    "dataset_dns.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_dns = dataset_dns.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_dns.replace(np.nan, 0, inplace=True)\n",
    "dataset_dns[' Label'].replace({\"BENIGN\": 0, \"DrDoS_DNS\": 3}, inplace=True)\n",
    "\n",
    "bengins_dns=dataset_dns.loc[dataset_dns[' Label']==0]\n",
    "\n",
    "dns=dataset_dns.loc[dataset_dns[' Label']==3]\n",
    "dns=dns.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_dns=bengins_dns.sample(n=int(DATA_COUNT/NO_CLASSES), random_state=1)\n",
    "bengins = bengins.append(bengins_dns)\n",
    "del dataset_dns\n",
    "del bengins_dns\n",
    "#bengins.shape, syns.shape, udps.shape,udpLags.shape,dns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDAP =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_ldap = pd.read_csv(os.path.join(dataset1_path,'DrDoS_LDAP.csv'))\n",
    "dataset_ldap.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_ldap =dataset_ldap.dropna()  # remove rows if any vlaue is none \n",
    "#dataset_ldap.replace(np.nan, 0, inplace=True)\n",
    "dataset_ldap[' Label'].replace({\"BENIGN\": 0, \"DrDoS_LDAP\": 4}, inplace=True)\n",
    "\n",
    "bengins_ldap=dataset_ldap.loc[dataset_ldap[' Label']==0]\n",
    "\n",
    "ldap=dataset_ldap.loc[dataset_ldap[' Label']==4]\n",
    "ldap=ldap.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_ldap=bengins_ldap.sample(n=int(DATA_COUNT/10), random_state=1)\n",
    "bengins = bengins.append(bengins_ldap)\n",
    "del dataset_ldap\n",
    "del bengins_ldap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETBIOS =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_bios = pd.read_csv(os.path.join(dataset1_path,'DrDoS_NetBIOS.csv'))\n",
    "dataset_bios.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_bios =dataset_bios.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_bios.replace(np.nan, 0, inplace=True)\n",
    "dataset_bios[' Label'].replace({\"BENIGN\": 0, \"DrDoS_NetBIOS\": 5}, inplace=True)\n",
    "\n",
    "bengins_bios=dataset_bios.loc[dataset_bios[' Label']==0]\n",
    "\n",
    "netbios=dataset_bios.loc[dataset_bios[' Label']==5]\n",
    "netbios=netbios.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_bios=bengins_bios.sample(n=int(DATA_COUNT/10), random_state=1)\n",
    "bengins = bengins.append(bengins_bios)\n",
    "del dataset_bios\n",
    "del bengins_bios\n",
    "# bengins.shape, syns.shape, udps.shape,udpLags.shape,dns.shape,ldap.shape,mssql.shape,netbios.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SNMP =6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_snmp = pd.read_csv(os.path.join(dataset1_path,'DrDoS_SNMP.csv'))\n",
    "dataset_snmp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_snmp =dataset_snmp.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_snmp.replace(np.nan, 0, inplace=True)\n",
    "dataset_snmp[' Label'].replace({\"BENIGN\": 0, \"DrDoS_SNMP\": 6}, inplace=True)\n",
    "\n",
    "bengins_snmp=dataset_snmp.loc[dataset_snmp[' Label']==0]\n",
    "\n",
    "snmp=dataset_snmp.loc[dataset_snmp[' Label']==6]\n",
    "snmp=snmp.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_snmp=bengins_snmp.sample(n=int(DATA_COUNT/10), random_state=1)\n",
    "bengins = bengins.append(bengins_snmp)\n",
    "del dataset_snmp\n",
    "del bengins_snmp\n",
    "# bengins.shape, syns.shape,udps.shape,udpLags.shape,dns.shape,ldap.shape,mssql.shape,netbios.shape,ntp.shape,snmp.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTP=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_ntp = pd.read_csv(os.path.join(dataset1_path,'DrDoS_NTP.csv'))\n",
    "dataset_ntp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_ntp =dataset_ntp.dropna()\n",
    "#dataset_ntp.replace(np.nan, 0, inplace=True)\n",
    "dataset_ntp[' Label'].replace({\"BENIGN\": 0, \"DrDoS_NTP\": 7}, inplace=True)\n",
    "\n",
    "bengins_ntp=dataset_ntp.loc[dataset_ntp[' Label']==0]\n",
    "\n",
    "ntp=dataset_ntp.loc[dataset_ntp[' Label']==7]\n",
    "ntp=ntp.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_ntp=bengins_ntp.sample(n=int(DATA_COUNT/NO_CLASSES), random_state=1)\n",
    "bengins = bengins.append(bengins_ntp)\n",
    "del dataset_ntp\n",
    "del bengins_ntp\n",
    "#bengins.shape, syns.shape, udps.shape,udpLags.shape,dns.shape,ldap.shape,mssql.shape,netbios.shape,ntp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFTP =8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tftp = pd.read_csv(os.path.join(dataset1_path,'TFTP.csv'),nrows=5000)\n",
    "dataset_tftp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_tftp =dataset_tftp.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_tftp.replace(np.nan, 0, inplace=True)\n",
    "dataset_tftp[' Label'].replace({\"BENIGN\": 0, \"TFTP\": 8}, inplace=True)\n",
    "\n",
    "tftp=dataset_tftp.loc[dataset_tftp[' Label']==8]\n",
    "tftp=tftp.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "del dataset_tftp\n",
    "\n",
    "# bengins.shape, syns.shape,udps.shape,udpLags.shape,dns.shape,ldap.shape,mssql.shape,netbios.shape,ntp.shape,snmp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYN FLOOD =9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zhJDoavDYzk",
    "outputId": "f058a52c-b3d9-41da-fc49-5a23617b366c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_syn = pd.read_csv(os.path.join(dataset1_path,'Syn.csv'))\n",
    "dataset_syn.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_syn =dataset_syn.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_syn.replace(np.nan, 0, inplace=True)\n",
    "dataset_syn[' Label'].replace({\"BENIGN\": 0, \"Syn\": 9}, inplace=True)\n",
    "bengins_syn=dataset_syn.loc[dataset_syn[' Label']==0]\n",
    "syns=dataset_syn.loc[dataset_syn[' Label']==9]\n",
    "\n",
    "syns=syns.sample(n=DATA_COUNT, random_state=1)\n",
    "bengins_syn=bengins_syn.sample(n=int(DATA_COUNT/NO_CLASSES), random_state=1)\n",
    "bengins = bengins.append(bengins_syn)\n",
    "del dataset_syn\n",
    "del bengins_syn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDP FLOOD =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_udp = pd.read_csv(os.path.join(dataset1_path,'DrDoS_UDP.csv'))\n",
    "dataset_udp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_udp =dataset_udp.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_udp.replace(np.nan, 0, inplace=True)\n",
    "dataset_udp[' Label'].replace({\"BENIGN\": 0, \"DrDoS_UDP\": 10}, inplace=True)\n",
    "\n",
    "bengins_udp=dataset_udp.loc[dataset_udp[' Label']==0]\n",
    "\n",
    "udps=dataset_udp.loc[dataset_udp[' Label']==10]\n",
    "udps=udps.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_udp=bengins_udp.sample(n=int(DATA_COUNT/NO_CLASSES), random_state=1)\n",
    "bengins = bengins.append(bengins_udp)\n",
    "\n",
    "del dataset_udp\n",
    "del bengins_udp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDP LAG =11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_udpLag = pd.read_csv(os.path.join(dataset1_path,'UDPLag.csv'))\n",
    "dataset_udpLag.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataset_udpLag =dataset_udpLag.dropna()  # remove rows if any vlaue is none\n",
    "#dataset_udpLag.replace(np.nan, 0, inplace=True)\n",
    "dataset_udpLag[' Label'].replace({\"BENIGN\": 0, \"UDP-lag\": 11}, inplace=True)\n",
    "bengins_udpLag=dataset_udpLag.loc[dataset_udpLag[' Label']==0]\n",
    "\n",
    "udpLags=dataset_udpLag.loc[dataset_udpLag[' Label']==11]\n",
    "udpLags=udpLags.sample(n=DATA_COUNT, random_state=1)\n",
    "\n",
    "bengins_udpLag=bengins_udpLag.sample(n=int(DATA_COUNT/10)*2, random_state=1)\n",
    "bengins = bengins.append(bengins_udpLag)\n",
    "del dataset_udpLag\n",
    "del bengins_udpLag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1050, 88), (1000, 88))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bengins.shape,mssql.shape#print the number of data and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lzShA0FTyOpL"
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([\n",
    "    bengins, \n",
    "    mssql,\n",
    "    ssdp,\n",
    "    dns,\n",
    "    ldap,   \n",
    "    netbios,\n",
    "    snmp,\n",
    "    ntp,\n",
    "    tftp,\n",
    "    syns,\n",
    "    udps,\n",
    "    udpLags], ignore_index=True, sort=False)\n",
    "#the final data set will be created by combining all the extracted data tousand per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYasiZ_1zEqb",
    "outputId": "544462af-5484-4af5-aa17-a493f47c82ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12050, 88)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape#check number of data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3OSwphoSIrGm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Flow ID            0\n",
       " Source IP         0\n",
       " Source Port       0\n",
       " Destination IP    0\n",
       "                  ..\n",
       " Idle Max          0\n",
       " Idle Min          0\n",
       "SimillarHTTP       0\n",
       " Inbound           0\n",
       " Label             0\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_nan = dataset.isnull().sum()\n",
    "check_nan#check if any more null values exsits in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7biYf_jEMovy",
    "outputId": "479f0f64-83e5-463a-f1ab-7a3136dbcdc0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "Flow ID\n",
      " Source IP\n",
      " Source Port\n",
      " Destination IP\n",
      " Destination Port\n",
      " Protocol\n",
      " Timestamp\n",
      " Flow Duration\n",
      " Total Fwd Packets\n",
      " Total Backward Packets\n",
      "Total Length of Fwd Packets\n",
      " Total Length of Bwd Packets\n",
      " Fwd Packet Length Max\n",
      " Fwd Packet Length Min\n",
      " Fwd Packet Length Mean\n",
      " Fwd Packet Length Std\n",
      "Bwd Packet Length Max\n",
      " Bwd Packet Length Min\n",
      " Bwd Packet Length Mean\n",
      " Bwd Packet Length Std\n",
      "Flow Bytes/s\n",
      " Flow Packets/s\n",
      " Flow IAT Mean\n",
      " Flow IAT Std\n",
      " Flow IAT Max\n",
      " Flow IAT Min\n",
      "Fwd IAT Total\n",
      " Fwd IAT Mean\n",
      " Fwd IAT Std\n",
      " Fwd IAT Max\n",
      " Fwd IAT Min\n",
      "Bwd IAT Total\n",
      " Bwd IAT Mean\n",
      " Bwd IAT Std\n",
      " Bwd IAT Max\n",
      " Bwd IAT Min\n",
      "Fwd PSH Flags\n",
      " Bwd PSH Flags\n",
      " Fwd URG Flags\n",
      " Bwd URG Flags\n",
      " Fwd Header Length\n",
      " Bwd Header Length\n",
      "Fwd Packets/s\n",
      " Bwd Packets/s\n",
      " Min Packet Length\n",
      " Max Packet Length\n",
      " Packet Length Mean\n",
      " Packet Length Std\n",
      " Packet Length Variance\n",
      "FIN Flag Count\n",
      " SYN Flag Count\n",
      " RST Flag Count\n",
      " PSH Flag Count\n",
      " ACK Flag Count\n",
      " URG Flag Count\n",
      " CWE Flag Count\n",
      " ECE Flag Count\n",
      " Down/Up Ratio\n",
      " Average Packet Size\n",
      " Avg Fwd Segment Size\n",
      " Avg Bwd Segment Size\n",
      " Fwd Header Length.1\n",
      "Fwd Avg Bytes/Bulk\n",
      " Fwd Avg Packets/Bulk\n",
      " Fwd Avg Bulk Rate\n",
      " Bwd Avg Bytes/Bulk\n",
      " Bwd Avg Packets/Bulk\n",
      "Bwd Avg Bulk Rate\n",
      "Subflow Fwd Packets\n",
      " Subflow Fwd Bytes\n",
      " Subflow Bwd Packets\n",
      " Subflow Bwd Bytes\n",
      "Init_Win_bytes_forward\n",
      " Init_Win_bytes_backward\n",
      " act_data_pkt_fwd\n",
      " min_seg_size_forward\n",
      "Active Mean\n",
      " Active Std\n",
      " Active Max\n",
      " Active Min\n",
      "Idle Mean\n",
      " Idle Std\n",
      " Idle Max\n",
      " Idle Min\n",
      "SimillarHTTP\n",
      " Inbound\n",
      " Label\n"
     ]
    }
   ],
   "source": [
    "for col in dataset.columns:\n",
    "    print(col)#iterate through colomns of the dataset and print the colomn names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VwUzNDhNhWqg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "object\n",
      "object\n",
      "int64\n",
      "object\n",
      "int64\n",
      "int64\n",
      "object\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "object\n",
      "int64\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "d=dataset.dtypes\n",
    "for i in d:\n",
    "  print(i)#print the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8ZzRCcjGfZCw"
   },
   "outputs": [],
   "source": [
    "dataset_balanced = shuffle(dataset)#shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "k_VkhFn3L_at"
   },
   "outputs": [],
   "source": [
    "x = dataset_balanced.drop([' Label','Unnamed: 0','Flow ID',' Source IP',' Destination IP',' Timestamp','SimillarHTTP'], axis=1)#remove data that are in object datatype and lable colomns( x are features)\n",
    "y = dataset_balanced[' Label'].astype('int')#extract lables from the dataset and convert to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([x, y], axis=1)# concatanate the processed dataset x as features and y as lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with key pairvalues to rename the colomns header\n",
    "names=[]\n",
    "for col in dataset.columns:\n",
    "\n",
    "    case = ('{}'.format(col),'{}'.format(col.strip()))\n",
    "    names.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameDict = {}\n",
    "\n",
    "for item in names:\n",
    "    nameDict[item[0]] = item[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Source Port': 'Source Port',\n",
       " ' Destination Port': 'Destination Port',\n",
       " ' Protocol': 'Protocol',\n",
       " ' Flow Duration': 'Flow Duration',\n",
       " ' Total Fwd Packets': 'Total Fwd Packets',\n",
       " ' Total Backward Packets': 'Total Backward Packets',\n",
       " 'Total Length of Fwd Packets': 'Total Length of Fwd Packets',\n",
       " ' Total Length of Bwd Packets': 'Total Length of Bwd Packets',\n",
       " ' Fwd Packet Length Max': 'Fwd Packet Length Max',\n",
       " ' Fwd Packet Length Min': 'Fwd Packet Length Min',\n",
       " ' Fwd Packet Length Mean': 'Fwd Packet Length Mean',\n",
       " ' Fwd Packet Length Std': 'Fwd Packet Length Std',\n",
       " 'Bwd Packet Length Max': 'Bwd Packet Length Max',\n",
       " ' Bwd Packet Length Min': 'Bwd Packet Length Min',\n",
       " ' Bwd Packet Length Mean': 'Bwd Packet Length Mean',\n",
       " ' Bwd Packet Length Std': 'Bwd Packet Length Std',\n",
       " 'Flow Bytes/s': 'Flow Bytes/s',\n",
       " ' Flow Packets/s': 'Flow Packets/s',\n",
       " ' Flow IAT Mean': 'Flow IAT Mean',\n",
       " ' Flow IAT Std': 'Flow IAT Std',\n",
       " ' Flow IAT Max': 'Flow IAT Max',\n",
       " ' Flow IAT Min': 'Flow IAT Min',\n",
       " 'Fwd IAT Total': 'Fwd IAT Total',\n",
       " ' Fwd IAT Mean': 'Fwd IAT Mean',\n",
       " ' Fwd IAT Std': 'Fwd IAT Std',\n",
       " ' Fwd IAT Max': 'Fwd IAT Max',\n",
       " ' Fwd IAT Min': 'Fwd IAT Min',\n",
       " 'Bwd IAT Total': 'Bwd IAT Total',\n",
       " ' Bwd IAT Mean': 'Bwd IAT Mean',\n",
       " ' Bwd IAT Std': 'Bwd IAT Std',\n",
       " ' Bwd IAT Max': 'Bwd IAT Max',\n",
       " ' Bwd IAT Min': 'Bwd IAT Min',\n",
       " 'Fwd PSH Flags': 'Fwd PSH Flags',\n",
       " ' Bwd PSH Flags': 'Bwd PSH Flags',\n",
       " ' Fwd URG Flags': 'Fwd URG Flags',\n",
       " ' Bwd URG Flags': 'Bwd URG Flags',\n",
       " ' Fwd Header Length': 'Fwd Header Length',\n",
       " ' Bwd Header Length': 'Bwd Header Length',\n",
       " 'Fwd Packets/s': 'Fwd Packets/s',\n",
       " ' Bwd Packets/s': 'Bwd Packets/s',\n",
       " ' Min Packet Length': 'Min Packet Length',\n",
       " ' Max Packet Length': 'Max Packet Length',\n",
       " ' Packet Length Mean': 'Packet Length Mean',\n",
       " ' Packet Length Std': 'Packet Length Std',\n",
       " ' Packet Length Variance': 'Packet Length Variance',\n",
       " 'FIN Flag Count': 'FIN Flag Count',\n",
       " ' SYN Flag Count': 'SYN Flag Count',\n",
       " ' RST Flag Count': 'RST Flag Count',\n",
       " ' PSH Flag Count': 'PSH Flag Count',\n",
       " ' ACK Flag Count': 'ACK Flag Count',\n",
       " ' URG Flag Count': 'URG Flag Count',\n",
       " ' CWE Flag Count': 'CWE Flag Count',\n",
       " ' ECE Flag Count': 'ECE Flag Count',\n",
       " ' Down/Up Ratio': 'Down/Up Ratio',\n",
       " ' Average Packet Size': 'Average Packet Size',\n",
       " ' Avg Fwd Segment Size': 'Avg Fwd Segment Size',\n",
       " ' Avg Bwd Segment Size': 'Avg Bwd Segment Size',\n",
       " ' Fwd Header Length.1': 'Fwd Header Length.1',\n",
       " 'Fwd Avg Bytes/Bulk': 'Fwd Avg Bytes/Bulk',\n",
       " ' Fwd Avg Packets/Bulk': 'Fwd Avg Packets/Bulk',\n",
       " ' Fwd Avg Bulk Rate': 'Fwd Avg Bulk Rate',\n",
       " ' Bwd Avg Bytes/Bulk': 'Bwd Avg Bytes/Bulk',\n",
       " ' Bwd Avg Packets/Bulk': 'Bwd Avg Packets/Bulk',\n",
       " 'Bwd Avg Bulk Rate': 'Bwd Avg Bulk Rate',\n",
       " 'Subflow Fwd Packets': 'Subflow Fwd Packets',\n",
       " ' Subflow Fwd Bytes': 'Subflow Fwd Bytes',\n",
       " ' Subflow Bwd Packets': 'Subflow Bwd Packets',\n",
       " ' Subflow Bwd Bytes': 'Subflow Bwd Bytes',\n",
       " 'Init_Win_bytes_forward': 'Init_Win_bytes_forward',\n",
       " ' Init_Win_bytes_backward': 'Init_Win_bytes_backward',\n",
       " ' act_data_pkt_fwd': 'act_data_pkt_fwd',\n",
       " ' min_seg_size_forward': 'min_seg_size_forward',\n",
       " 'Active Mean': 'Active Mean',\n",
       " ' Active Std': 'Active Std',\n",
       " ' Active Max': 'Active Max',\n",
       " ' Active Min': 'Active Min',\n",
       " 'Idle Mean': 'Idle Mean',\n",
       " ' Idle Std': 'Idle Std',\n",
       " ' Idle Max': 'Idle Max',\n",
       " ' Idle Min': 'Idle Min',\n",
       " ' Inbound': 'Inbound',\n",
       " ' Label': 'Label'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns=nameDict,\n",
    "          inplace=True)\n",
    "# remove spaces infront of colomns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Port\n",
      "Destination Port\n",
      "Protocol\n",
      "Flow Duration\n",
      "Total Fwd Packets\n",
      "Total Backward Packets\n",
      "Total Length of Fwd Packets\n",
      "Total Length of Bwd Packets\n",
      "Fwd Packet Length Max\n",
      "Fwd Packet Length Min\n",
      "Fwd Packet Length Mean\n",
      "Fwd Packet Length Std\n",
      "Bwd Packet Length Max\n",
      "Bwd Packet Length Min\n",
      "Bwd Packet Length Mean\n",
      "Bwd Packet Length Std\n",
      "Flow Bytes/s\n",
      "Flow Packets/s\n",
      "Flow IAT Mean\n",
      "Flow IAT Std\n",
      "Flow IAT Max\n",
      "Flow IAT Min\n",
      "Fwd IAT Total\n",
      "Fwd IAT Mean\n",
      "Fwd IAT Std\n",
      "Fwd IAT Max\n",
      "Fwd IAT Min\n",
      "Bwd IAT Total\n",
      "Bwd IAT Mean\n",
      "Bwd IAT Std\n",
      "Bwd IAT Max\n",
      "Bwd IAT Min\n",
      "Fwd PSH Flags\n",
      "Bwd PSH Flags\n",
      "Fwd URG Flags\n",
      "Bwd URG Flags\n",
      "Fwd Header Length\n",
      "Bwd Header Length\n",
      "Fwd Packets/s\n",
      "Bwd Packets/s\n",
      "Min Packet Length\n",
      "Max Packet Length\n",
      "Packet Length Mean\n",
      "Packet Length Std\n",
      "Packet Length Variance\n",
      "FIN Flag Count\n",
      "SYN Flag Count\n",
      "RST Flag Count\n",
      "PSH Flag Count\n",
      "ACK Flag Count\n",
      "URG Flag Count\n",
      "CWE Flag Count\n",
      "ECE Flag Count\n",
      "Down/Up Ratio\n",
      "Average Packet Size\n",
      "Avg Fwd Segment Size\n",
      "Avg Bwd Segment Size\n",
      "Fwd Header Length.1\n",
      "Fwd Avg Bytes/Bulk\n",
      "Fwd Avg Packets/Bulk\n",
      "Fwd Avg Bulk Rate\n",
      "Bwd Avg Bytes/Bulk\n",
      "Bwd Avg Packets/Bulk\n",
      "Bwd Avg Bulk Rate\n",
      "Subflow Fwd Packets\n",
      "Subflow Fwd Bytes\n",
      "Subflow Bwd Packets\n",
      "Subflow Bwd Bytes\n",
      "Init_Win_bytes_forward\n",
      "Init_Win_bytes_backward\n",
      "act_data_pkt_fwd\n",
      "min_seg_size_forward\n",
      "Active Mean\n",
      "Active Std\n",
      "Active Max\n",
      "Active Min\n",
      "Idle Mean\n",
      "Idle Std\n",
      "Idle Max\n",
      "Idle Min\n",
      "Inbound\n",
      "Label\n"
     ]
    }
   ],
   "source": [
    "for col in dataset.columns:\n",
    "    print(col)\n",
    "    #print colomn names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data1\\\\balanced_all_12_processed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-23339e6c83d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset1_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"balanced_all_12_processed.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#save the dataset as a csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data1\\\\balanced_all_12_processed.csv'"
     ]
    }
   ],
   "source": [
    "dataset.to_csv(os.path.join(dataset1_path,\"balanced_all_12_processed.csv\"), encoding='utf-8', index=False)\n",
    "#save the dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
